{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-27T04:41:58.237989Z","iopub.execute_input":"2023-09-27T04:41:58.238418Z","iopub.status.idle":"2023-09-27T04:41:58.768872Z","shell.execute_reply.started":"2023-09-27T04:41:58.238377Z","shell.execute_reply":"2023-09-27T04:41:58.767695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport tensorflow as tf\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error, accuracy_score","metadata":{"execution":{"iopub.status.busy":"2023-09-27T04:55:28.659091Z","iopub.execute_input":"2023-09-27T04:55:28.659454Z","iopub.status.idle":"2023-09-27T04:55:28.665854Z","shell.execute_reply.started":"2023-09-27T04:55:28.659426Z","shell.execute_reply":"2023-09-27T04:55:28.664861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/titanic/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-09-27T04:42:11.257315Z","iopub.execute_input":"2023-09-27T04:42:11.258359Z","iopub.status.idle":"2023-09-27T04:42:11.291278Z","shell.execute_reply.started":"2023-09-27T04:42:11.258321Z","shell.execute_reply":"2023-09-27T04:42:11.290230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove rows with missing target, separate target from predictors\ntrain_df.dropna(axis=0, subset=['Survived'], inplace=True)\ny = train_df.Survived\ntrain_df.drop(['Survived'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-27T04:42:11.296898Z","iopub.execute_input":"2023-09-27T04:42:11.297235Z","iopub.status.idle":"2023-09-27T04:42:11.325919Z","shell.execute_reply.started":"2023-09-27T04:42:11.297204Z","shell.execute_reply":"2023-09-27T04:42:11.324779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Break off validation set from training data\nX_train, X_valid, y_train, y_valid = train_test_split(train_df, y, \n                                                                train_size=0.8, test_size=0.2,\n                                                                random_state=0)","metadata":{"execution":{"iopub.status.busy":"2023-09-27T04:42:11.327671Z","iopub.execute_input":"2023-09-27T04:42:11.328403Z","iopub.status.idle":"2023-09-27T04:42:11.336641Z","shell.execute_reply.started":"2023-09-27T04:42:11.328365Z","shell.execute_reply":"2023-09-27T04:42:11.335613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# \"Cardinality\" means the number of unique values in a column\n# Select categorical columns with relatively low cardinality (convenient but arbitrary)\ncategorical_cols = [cname for cname in X_train.columns if\n                    X_train[cname].nunique() < 10 and \n                    X_train[cname].dtype == \"object\"]\n\n# Select numerical columns\nnumerical_cols = [cname for cname in X_train.columns if \n                X_train[cname].dtype in ['int64', 'float64']]\n\n# Keep selected columns only\nmy_cols = categorical_cols + numerical_cols\nX_train = X_train[my_cols].copy()\nX_valid = X_valid[my_cols].copy()\nX_test = test_df[my_cols].copy()","metadata":{"execution":{"iopub.status.busy":"2023-09-27T04:42:11.338877Z","iopub.execute_input":"2023-09-27T04:42:11.340165Z","iopub.status.idle":"2023-09-27T04:42:11.363368Z","shell.execute_reply.started":"2023-09-27T04:42:11.340128Z","shell.execute_reply":"2023-09-27T04:42:11.362068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocessing for numerical data\nnumerical_transformer = SimpleImputer(strategy='most_frequent')\n\n# Preprocessing for categorical data\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder())\n])\n\n# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])","metadata":{"execution":{"iopub.status.busy":"2023-09-27T04:42:11.365078Z","iopub.execute_input":"2023-09-27T04:42:11.365807Z","iopub.status.idle":"2023-09-27T04:42:11.372584Z","shell.execute_reply.started":"2023-09-27T04:42:11.365770Z","shell.execute_reply":"2023-09-27T04:42:11.371560Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBRegressor, XGBClassifier\n\n# Define model\n\nX_train_transformed = preprocessor.fit_transform(X_train)\nX_valid_transformed = preprocessor.transform(X_valid)\n\ndef xgb_model(n_est, lr, pred):\n    xg_model = XGBClassifier(n_estimators=n_est, learning_rate=lr)\n    xg_model.fit(X_train_transformed, y_train, eval_set=[(X_valid_transformed, y_valid)], verbose=False)\n    preds = xg_model.predict(pred)\n    mae = mean_absolute_error(y_valid, preds)\n    acc = accuracy_score(y_valid, preds)\n\n   # print(f\"MAE: {mae}\")\n    return xg_model, mae, acc\n\nbest_mae = float('inf')\nbest_model = None\nbest_acc = 0 \n\nn_values = np.linspace(180, 220, 25)\nl_values = np.linspace(0.09, 0.11, 20)\n\n# Hyperparameter tuning\nfor n in n_values:\n    for l in l_values:\n        model, mae, acc = xgb_model(int(n), l, X_valid_transformed)\n        print(f\"N est: {n}, lr: {l}, ACC: {acc}\")\n        if acc > best_acc:\n            best_acc = acc\n            best_model = model","metadata":{"execution":{"iopub.status.busy":"2023-09-27T05:05:31.021777Z","iopub.execute_input":"2023-09-27T05:05:31.022138Z","iopub.status.idle":"2023-09-27T05:07:26.665914Z","shell.execute_reply.started":"2023-09-27T05:05:31.022112Z","shell.execute_reply":"2023-09-27T05:07:26.665147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"best_model","metadata":{}},{"cell_type":"code","source":"# Make predictions using the best model\nbest_preds = best_model.predict(X_valid_transformed)\n\n# Compute accuracy\nbest_model_accuracy = accuracy_score(y_valid, best_preds)\n\nbest_model_accuracy","metadata":{"execution":{"iopub.status.busy":"2023-09-27T05:07:26.669651Z","iopub.execute_input":"2023-09-27T05:07:26.671763Z","iopub.status.idle":"2023-09-27T05:07:26.682599Z","shell.execute_reply.started":"2023-09-27T05:07:26.671719Z","shell.execute_reply":"2023-09-27T05:07:26.681797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Make predictions on test data using the best model\nX_test_transformed = preprocessor.transform(X_test)\ntest_preds = best_model.predict(X_test_transformed)\n\npassenger_id_to_prediction = dict(zip(X_test['PassengerId'], test_preds))\n\ndf = pd.DataFrame(list(passenger_id_to_prediction.items()), columns=['PassengerId', 'Survived'])\ndf.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")\n","metadata":{"execution":{"iopub.status.busy":"2023-09-27T05:07:32.386555Z","iopub.execute_input":"2023-09-27T05:07:32.386937Z","iopub.status.idle":"2023-09-27T05:07:32.414731Z","shell.execute_reply.started":"2023-09-27T05:07:32.386908Z","shell.execute_reply":"2023-09-27T05:07:32.413838Z"},"trusted":true},"execution_count":null,"outputs":[]}]}